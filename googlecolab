%pwd  

%cd '/content'

!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1XdwGEqKXeKH1NRhZXxCZo5T8mncwYHCC' -O ./Bet-n-dcm2nii.zip
!unzip -q ./Bet-n-dcm2nii.zip
!rm -rf images

!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1MqEWwsrYvG1Dqdez1F2kRbfcLGTagFJl' -O ./LGGtestpat.zip
!unzip -q ./LGGtestpat
!rm -rf _MACOSX
!rm -rf LGGtestpat/.DS_Store
!rm -rf LGGtestpat/S2/.DS_Store
!rm -rf LGGtestpat/S3/.DS_Store

!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1uBQdQIYcA_ACqycw8ofDzD-1G9YwZaRw' -O ./icbm152t2.zip
!unzip -q ./icbm152t2.zip

NIFTI_PATH = './LGGtestpat'

import os, fnmatch

os.environ['FSLOUTPUTTYPE'] = 'NIFTI_GZ'

for subj in os.listdir(NIFTI_PATH):
    subj_path = os.path.join(NIFTI_PATH, subj)
    print ("Working on " + subj_path)
    series = fnmatch.filter(os.listdir(subj_path), '*.nii.gz')
    for ser in ['T2']:
        nii_file = os.path.join (subj_path, ser)
# First, perform N4 bias correction. Not required, but may improve results. Also must track new names
        new_file = os.path.join (subj_path, 'N4-' + ser)
        cmd = "./N4BiasFieldCorrection -i %s.nii.gz -o %s.nii.gz" % (nii_file, new_file)
        os.system(cmd)
        print (cmd)
        
        
# Next, Register the images to the avg 152 t2 image from MNI
for subj in os.listdir(NIFTI_PATH):
    subj_path = os.path.join(NIFTI_PATH, subj)
    print ("Working on " + subj_path)
    series = fnmatch.filter(os.listdir(subj_path), 'N4*')
    for ser in ['T2']:   
        MNI_file = './icbm_avg_152_t2_tal_lin.nii'
        T2_file =  os.path.join (subj_path, 'N4-T2.nii.gz')
        new_file = os.path.join (subj_path, 'Reg-N4-T2.nii.gz')
        cmd = "./flirt -in %s -ref %s  -out %s" % (T2_file, MNI_file, new_file)
        os.system(cmd)
        print (cmd)
        
# then import the excel file which was saved as a .csv  no zip is required        
        
import pandas as pd

!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1z2GmRDDVMbcb1x26jlA9X0M4WAv4-kvA' -O ./TumorSlices.csv
df = pd.read_csv ('./TumorSlices.csv')
print (df) 


# Cell #5
# create new versions of the T1, GAD, and T2 images that range from 0 to 255, and where the 0 intensity value maps to the 5th percentile value 
# and 255 maps to the 95th percentile value.
import imageio
import nibabel as nib
import numpy as np

MIN_MR = 20

def rescale_5_95_percentile(image):
    dims = np.shape(image)
    image_1d = image.reshape(1, image.size)
    above = np.where(image_1d>MIN_MR, image_1d, image_1d)
    if above.size < image_1d.size/2:
        above = image_1d # avoid bad MIN_MR thresholds
    sorted_im = np.sort(above, axis = None)
    
    start = int(sorted_im.size / 20)  # 20 = 5%
    end = int(sorted_im.size * 19 / 20) # 95%
    start_val = sorted_im[start]
    end_val = sorted_im[end]
    
    image = np.maximum(image, start_val) # map values below the start_val to start_val
    image = np.minimum(image, end_val)   # map values above the end_val to end_val
    image = image - start_val # subtract the starting intensity

 #   print ("rescaling range " + str(newmin) + " to " + str(histo[1][index]))
    image = (np.maximum(image, 0) / image.max()) * 255.0
    return image

def nifti_to_img(red_file, green_file, blue_file, not_dir, yes_dir, startSlice, endSlice, subject):
### red_ green_ and blue_files are the nifit files that will be combined to go into the PNG
### not_dir is the direcotry where PNGs are stored if they are not in the (inclusive)
### range set by startSlice/endSlice
### yes_dir is where they are stored when they ARE in the range
### subject is the ID so that we can track where images came from

    try:
        nifti = nib.load(red_file)
        nif_header = nifti.header
        red_image = nifti.get_fdata()
    except:
        return 0

    try:
        if os.path.isfile(green_file):
            nifti = nib.load(green_file)
            nif_header = nifti.header
            green_image = nifti.get_fdata()
        else:
            pass
    except:  # if can't load, then use red image
        green_image = red_image
    
    try:
        if os.path.isfile(blue_file):
            nifti = nib.load(blue_file)

            nif_header = nifti.header
            blue_image = nifti.get_fdata()
        else:
            pass
    except:  # if can't load, then use red image
        blue_image = red_image
        
# now scale the intensity for each image        
    red_image = rescale_5_95_percentile(red_image)
    green_image = rescale_5_95_percentile(green_image)
    blue_image = rescale_5_95_percentile(blue_image)
# then convert to 8 bits
    red_image = red_image.astype(np.uint8)     
    green_image = green_image.astype(np.uint8)     
    blue_image = blue_image.astype(np.uint8)   
    
# get the number of slices
    dims = np.shape(red_image)
    zd = dims[2]

    for z in range(0, zd):
        outname = subject + "-{0:04d}".format(z) + '.png'
        if z >= startSlice and z <= endSlice:  # this is enhancing
            out_dir = yes_dir
        else:
            out_dir = not_dir
        outname = os.path.join(out_dir, outname)
        if not os.path.exists(out_dir):
            os.makedirs(out_dir)
        combined = np.dstack((red_image[:,:,z],green_image[:,:,z],
                              blue_image[:,:,z]))
## . images come in rotated
        combined = np.rot90(combined, k=1)
#        print ('Name: ' + outname)
        imageio.imwrite(outname, combined)
    return zd

# Cell #6
# take the GAD nii, scale it to 0-255 and store that into the red channel
# same for T1 (green) and T2 (blue)
# PNG files are stored in enh / nonenh folders based on the csv file

# store the png files into enhancing or nonenhancing folders after making sure they are cleared

!rm -rf classified

!mkdir classified

for subj in os.listdir(NIFTI_PATH):
    subj_path = os.path.join(NIFTI_PATH, subj)
    red_f = os.path.join(subj_path, 'Reg-N4-T2.nii.gz')
    startSlice = df.loc[df.Subject == subj, 'StartSlice'].values[0]
    endSlice = df.loc[df.Subject == subj, 'EndSlice'].values[0]
    print ("Making PNG file for " + subj + " start: " + str(startSlice) + " end: " + str(endSlice))
    count = nifti_to_img(red_f, red_f, red_f,'./classified/not', './classified/enh', startSlice, endSlice, subj)
    
    
# Cell #7
# now we are ready to load data and train classifier
# while we did this in separate cells before, we will do it all in one
# this should look familiar.
import numpy as np
import tensorflow as tf
!pip install tensornets
import tensornets as nets
import tensorflow_hub as hub
import keras
import tensorflow.keras 
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense,GlobalAveragePooling2D
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.applications.imagenet_utils import decode_predictions
from tensorflow.keras.applications.nasnet import NASNetLarge, NASNetMobile, preprocess_input
directory = "./classified"

base_model=tensorflow.keras.applications.nasnet.NASNetLarge(input_shape=(331, 331, 3), include_top=False, weights='imagenet', input_tensor=None, pooling=None) #imports the nasnet large model and discards the last 1000 neuron layer.

x=base_model.output
x=GlobalAveragePooling2D()(x)
x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.
x=Dense(1024,activation='relu')(x) #dense layer 2
x=Dense(512,activation='relu')(x) #dense layer 3
preds=Dense(2,activation='softmax')(x) #final layer with softmax activation, for 2 classes

model=Model(inputs=base_model.input,outputs=preds) # to load saved model with weights use model= tensorflow.keras.models.load_model('myLGGtestmodel.h5')
#specify the inputs
#specify the outputs
#now a model has been created based on our architecture

for i,layer in enumerate(model.layers):
  print(i,layer.name)

for layer in model.layers:
    layer.trainable=False
# or if we want to set the first 20 layers of the network to be non-trainable
for layer in model.layers[:1039]:
    layer.trainable=False
for layer in model.layers[1039:]:
    layer.trainable=True

train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies
# add the directory below very important ##########################

train_generator=train_datagen.flow_from_directory('./classified',
                                                 target_size=(331,331),
                                                 color_mode='rgb',
                                                 batch_size=32,
                                                 class_mode='categorical',
                                                 shuffle=True)


model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])
# Adam optimizer
# loss function will be categorical cross entropy
# evaluation metric will be accuracy

step_size_train=train_generator.n//train_generator.batch_size
model.fit_generator(generator=train_generator,
                   steps_per_epoch=step_size_train,
                   epochs=10)
    
# next cell to save model including newly trained weights
model.save('myLGGtestmodel.h5') # rename it how you like, it will show up in your directory. I have explained above using a hastag how and where to load the model.
